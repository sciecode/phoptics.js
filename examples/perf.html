<html>

<head>
  <title>Phoptic.js - Perf</title>
  <style>
    html,
    body {
      margin: 0;
      background-color: rgba(.3, .3, .3, 1);
    }

    canvas {
      width: 100%;
      height: 100vh;
    }
  </style>
  <script type="importmap">
      {
        "imports": {
          "phoptics": "../src/engine/export.mjs",
          "phoptics/math": "../src/datatypes/export.mjs",
          "phoptics/utils/": "../src/utils/"
        }
      }
    </script>
</head>

<body>
  <script type="module">
    import {
      Engine, Mesh, Vertex, Instance, RenderList, Shader, Material, Texture, CanvasTexture,
      RenderPass, RenderTarget, StructuredBuffer, Format
    } from 'phoptics';
    import { Vec3, Vec4, Quat, Mat3x4, Mat4x4 } from 'phoptics/math';
    import { ShaderLib } from 'phoptics/utils/modules/shaders/shader_lib.mjs';
    import { builtin } from 'phoptics/utils/modules/shaders/builtin.mjs';
    import { uncompress } from 'phoptics/utils/modules/geometry/compression.mjs';

    import instancing_shader from "./assets/shaders/objects/instancing_shader.mjs";

    const dpr = window.devicePixelRatio;
    let shader_lib = new ShaderLib(builtin);
    let viewport = { width: window.innerWidth * dpr | 0, height: window.innerHeight * dpr | 0 };
    let engine, canvas_texture, render_pass, render_target, scene, camera;
    let target = new Vec3();

    const renderlist = new RenderList();

    (async () => {
      engine = new Engine(await Engine.acquire_device());

      canvas_texture = new CanvasTexture({ format: Engine.canvas_format() });
      canvas_texture.set_size(viewport);
      document.body.append(canvas_texture.canvas);

      camera = new StructuredBuffer([
        { name: "projection", type: Mat4x4 },
        { name: "view", type: Mat3x4 },
        { name: "position", type: Vec4 },
        { name: "luma", type: Vec4 },
      ]);

      render_pass = new RenderPass({
        multisampled: true,
        formats: {
          color: [canvas_texture.format],
          depth: Format.DEPTH32,
        },
        bindings: [{ name: "camera", resource: camera }]
      });

      const multisampled_texture = new Texture({
        renderable: true, multisampled: true,
        size: viewport, format: canvas_texture.format
      });
      const depth_texture = new Texture({
        renderable: true, multisampled: true,
        size: viewport, format: render_pass.formats.depth
      });

      render_target = new RenderTarget({
        color: [{
          view: multisampled_texture.create_view(),
          resolve: canvas_texture.create_view(),
          clear: [.05, .05, .05, 0]
        }],
        depth: { view: depth_texture.create_view(), clear: 0 }
      });

      render_pass.set_render_target(render_target);

      target.set(0, 1, 0);
      camera.position.set(0, 0, 100);
      const exposure = calc_tonemap(1, 250);
      camera.luma.set(exposure.r_nits, exposure.r_nb);
      camera.view.translate(camera.position).look_at(target).view_inverse();
      camera.projection.perspective(Math.PI / 3, viewport.width / viewport.height, 1, 600);

      const material = new Material({ shader: shader_lib.process(instancing_shader) });

      const query = await fetch('./assets/models/walt.phg');
      const compressed = new Uint8Array(await query.arrayBuffer());
      const geo = uncompress(compressed);

      const count = 4000;
      const mat = new Mat3x4(), vec = new Vec4(), q = new Quat();
      let instanced_dynamic = new Float32Array(count * 16);
      for (let i = 0; i < instanced_dynamic.length; i += 16) {
        vec.set(Math.random(), Math.random(), Math.random()).sub_f32(.5).mul_f32(100);
        q.set().rot_y((Math.random() - .5) * Math.PI / 2);
        mat.rigid(vec, q).to(instanced_dynamic, i);
        vec.set(Math.random(), Math.random(), Math.random()).to(instanced_dynamic, i + 12);
      }

      geo.attributes.instances.push(new Instance({ data: instanced_dynamic, stride: 16 }));
      geo.draw.instance_count = count;

      const mesh = new Mesh(geo, material);
      renderlist.add(mesh);

      requestAnimationFrame(animate);
    })();

    const calc_tonemap = (ev2, nits) => {
      let r_nits = 1 / nits;
      let r_nb = .5 * (2 ** ev2) * r_nits;
      return { r_nits, r_nb };
    };

    const auto_resize = () => {
      const dpr = window.devicePixelRatio;
      const newW = (canvas_texture.canvas.clientWidth * dpr) | 0;
      const newH = (canvas_texture.canvas.clientHeight * dpr) | 0;

      if (viewport.width != newW || viewport.height != newH) {
        viewport.width = newW; viewport.height = newH;
        render_target.set_size(viewport);

        camera.projection.perspective(Math.PI / 3, viewport.width / viewport.height, 1, 300);
        camera.update();
      }
    };

    const animate = () => {
      requestAnimationFrame(animate);

      auto_resize();

      engine.render(render_pass, renderlist);
    }
  </script>
</body>

</html>